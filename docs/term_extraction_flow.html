<!DOCTYPE html>
<html>
<head>
<title>term_extraction_flow.md</title>
<meta http-equiv="Content-type" content="text/html;charset=UTF-8">

<style>
/* https://github.com/microsoft/vscode/blob/master/extensions/markdown-language-features/media/markdown.css */
/*---------------------------------------------------------------------------------------------
 *  Copyright (c) Microsoft Corporation. All rights reserved.
 *  Licensed under the MIT License. See License.txt in the project root for license information.
 *--------------------------------------------------------------------------------------------*/

body {
	font-family: var(--vscode-markdown-font-family, -apple-system, BlinkMacSystemFont, "Segoe WPC", "Segoe UI", "Ubuntu", "Droid Sans", sans-serif);
	font-size: var(--vscode-markdown-font-size, 14px);
	padding: 0 26px;
	line-height: var(--vscode-markdown-line-height, 22px);
	word-wrap: break-word;
}

#code-csp-warning {
	position: fixed;
	top: 0;
	right: 0;
	color: white;
	margin: 16px;
	text-align: center;
	font-size: 12px;
	font-family: sans-serif;
	background-color:#444444;
	cursor: pointer;
	padding: 6px;
	box-shadow: 1px 1px 1px rgba(0,0,0,.25);
}

#code-csp-warning:hover {
	text-decoration: none;
	background-color:#007acc;
	box-shadow: 2px 2px 2px rgba(0,0,0,.25);
}

body.scrollBeyondLastLine {
	margin-bottom: calc(100vh - 22px);
}

body.showEditorSelection .code-line {
	position: relative;
}

body.showEditorSelection .code-active-line:before,
body.showEditorSelection .code-line:hover:before {
	content: "";
	display: block;
	position: absolute;
	top: 0;
	left: -12px;
	height: 100%;
}

body.showEditorSelection li.code-active-line:before,
body.showEditorSelection li.code-line:hover:before {
	left: -30px;
}

.vscode-light.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(0, 0, 0, 0.15);
}

.vscode-light.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(0, 0, 0, 0.40);
}

.vscode-light.showEditorSelection .code-line .code-line:hover:before {
	border-left: none;
}

.vscode-dark.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(255, 255, 255, 0.4);
}

.vscode-dark.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(255, 255, 255, 0.60);
}

.vscode-dark.showEditorSelection .code-line .code-line:hover:before {
	border-left: none;
}

.vscode-high-contrast.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(255, 160, 0, 0.7);
}

.vscode-high-contrast.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(255, 160, 0, 1);
}

.vscode-high-contrast.showEditorSelection .code-line .code-line:hover:before {
	border-left: none;
}

img {
	max-width: 100%;
	max-height: 100%;
}

a {
	text-decoration: none;
}

a:hover {
	text-decoration: underline;
}

a:focus,
input:focus,
select:focus,
textarea:focus {
	outline: 1px solid -webkit-focus-ring-color;
	outline-offset: -1px;
}

hr {
	border: 0;
	height: 2px;
	border-bottom: 2px solid;
}

h1 {
	padding-bottom: 0.3em;
	line-height: 1.2;
	border-bottom-width: 1px;
	border-bottom-style: solid;
}

h1, h2, h3 {
	font-weight: normal;
}

table {
	border-collapse: collapse;
}

table > thead > tr > th {
	text-align: left;
	border-bottom: 1px solid;
}

table > thead > tr > th,
table > thead > tr > td,
table > tbody > tr > th,
table > tbody > tr > td {
	padding: 5px 10px;
}

table > tbody > tr + tr > td {
	border-top: 1px solid;
}

blockquote {
	margin: 0 7px 0 5px;
	padding: 0 16px 0 10px;
	border-left-width: 5px;
	border-left-style: solid;
}

code {
	font-family: Menlo, Monaco, Consolas, "Droid Sans Mono", "Courier New", monospace, "Droid Sans Fallback";
	font-size: 1em;
	line-height: 1.357em;
}

body.wordWrap pre {
	white-space: pre-wrap;
}

pre:not(.hljs),
pre.hljs code > div {
	padding: 16px;
	border-radius: 3px;
	overflow: auto;
}

pre code {
	color: var(--vscode-editor-foreground);
	tab-size: 4;
}

/** Theming */

.vscode-light pre {
	background-color: rgba(220, 220, 220, 0.4);
}

.vscode-dark pre {
	background-color: rgba(10, 10, 10, 0.4);
}

.vscode-high-contrast pre {
	background-color: rgb(0, 0, 0);
}

.vscode-high-contrast h1 {
	border-color: rgb(0, 0, 0);
}

.vscode-light table > thead > tr > th {
	border-color: rgba(0, 0, 0, 0.69);
}

.vscode-dark table > thead > tr > th {
	border-color: rgba(255, 255, 255, 0.69);
}

.vscode-light h1,
.vscode-light hr,
.vscode-light table > tbody > tr + tr > td {
	border-color: rgba(0, 0, 0, 0.18);
}

.vscode-dark h1,
.vscode-dark hr,
.vscode-dark table > tbody > tr + tr > td {
	border-color: rgba(255, 255, 255, 0.18);
}

</style>

<style>
/* Tomorrow Theme */
/* http://jmblog.github.com/color-themes-for-google-code-highlightjs */
/* Original theme - https://github.com/chriskempson/tomorrow-theme */

/* Tomorrow Comment */
.hljs-comment,
.hljs-quote {
	color: #8e908c;
}

/* Tomorrow Red */
.hljs-variable,
.hljs-template-variable,
.hljs-tag,
.hljs-name,
.hljs-selector-id,
.hljs-selector-class,
.hljs-regexp,
.hljs-deletion {
	color: #c82829;
}

/* Tomorrow Orange */
.hljs-number,
.hljs-built_in,
.hljs-builtin-name,
.hljs-literal,
.hljs-type,
.hljs-params,
.hljs-meta,
.hljs-link {
	color: #f5871f;
}

/* Tomorrow Yellow */
.hljs-attribute {
	color: #eab700;
}

/* Tomorrow Green */
.hljs-string,
.hljs-symbol,
.hljs-bullet,
.hljs-addition {
	color: #718c00;
}

/* Tomorrow Blue */
.hljs-title,
.hljs-section {
	color: #4271ae;
}

/* Tomorrow Purple */
.hljs-keyword,
.hljs-selector-tag {
	color: #8959a8;
}

.hljs {
	display: block;
	overflow-x: auto;
	color: #4d4d4c;
	padding: 0.5em;
}

.hljs-emphasis {
	font-style: italic;
}

.hljs-strong {
	font-weight: bold;
}
</style>

<style>
/*
 * Markdown PDF CSS
 */

 body {
	font-family: -apple-system, BlinkMacSystemFont, "Segoe WPC", "Segoe UI", "Ubuntu", "Droid Sans", sans-serif, "Meiryo";
	padding: 0 12px;
}

pre {
	background-color: #f8f8f8;
	border: 1px solid #cccccc;
	border-radius: 3px;
	overflow-x: auto;
	white-space: pre-wrap;
	overflow-wrap: break-word;
}

pre:not(.hljs) {
	padding: 23px;
	line-height: 19px;
}

blockquote {
	background: rgba(127, 127, 127, 0.1);
	border-color: rgba(0, 122, 204, 0.5);
}

.emoji {
	height: 1.4em;
}

code {
	font-size: 14px;
	line-height: 19px;
}

/* for inline code */
:not(pre):not(.hljs) > code {
	color: #C9AE75; /* Change the old color so it seems less like an error */
	font-size: inherit;
}

/* Page Break : use <div class="page"/> to insert page break
-------------------------------------------------------- */
.page {
	page-break-after: always;
}

</style>

<script src="https://unpkg.com/mermaid@10.4.0/dist/mermaid.min.js"></script>
</head>
<body>
  <script>
    mermaid.initialize({
      startOnLoad: true,
      theme: document.body.classList.contains('vscode-dark') || document.body.classList.contains('vscode-high-contrast')
          ? 'dark'
          : 'default'
    });
  </script>
<h1 id="%E7%94%A8%E8%AA%9E%E6%8A%BD%E5%87%BA%E3%83%95%E3%83%AD%E3%83%BC">用語抽出フロー</h1>
<h2 id="%E3%82%B7%E3%83%BC%E3%82%B1%E3%83%B3%E3%82%B9%E5%9B%B3">シーケンス図</h2>
<pre><code class="language-mermaid"><div class="mermaid">sequenceDiagram
    participant User as ユーザー
    participant UI as Streamlit UI
    participant TE as TermExtraction
    participant SE as StatisticalExtractor
    participant SR as SemReRank
    participant VS as VectorStore
    participant LLM as Azure OpenAI (LLM)
    participant ESS as ExtractSemanticSynonyms
    participant TCA as TermClusteringAnalyzer
    participant DB as PostgreSQL

    User->>UI: PDFアップロード
    UI->>TE: extract_terms_from_documents()

    Note over TE: Phase 1: 候補抽出
    loop 各ドキュメント
        TE->>SE: extract_candidates(text)
        SE->>SE: Sudachi形態素解析 (C mode)
        SE->>SE: 複合語抽出 (N-gram, 名詞連続)
        SE-->>TE: 候補用語 + 頻度
    end

    Note over TE: Phase 2: 統計スコア計算
    TE->>SE: calculate_tfidf(documents, candidates)
    SE-->>TE: TF-IDFスコア
    TE->>SE: calculate_cvalue(candidates, full_text)
    SE-->>TE: C-valueスコア
    TE->>SE: calculate_combined_scores (Stage A: seed)
    SE-->>TE: シードスコア (C-value重視)
    TE->>SE: calculate_combined_scores (Stage B: final)
    SE-->>TE: 基底スコア (TF-IDF重視)

    Note over TE: Phase 3: 略語ボーナス
    TE->>TE: 略語パターン判定 (^[A-Z]{2,5}$)
    TE->>TE: 略語スコア × 1.3

    Note over TE: Phase 4: SemReRank
    TE->>SR: enhance_scores(candidates, base_scores, seed_scores)
    SR->>SR: グラフ構築 (用語間類似度)
    SR->>SR: PageRank実行
    SR->>SR: 最終スコア = base × (1 + α × pagerank)
    SR-->>TE: 強化スコア

    Note over TE: Phase 5: 表記ゆれ・関連語検出
    TE->>SE: detect_variants(candidates)
    SE->>SE: Levenshtein距離 + カタカナ正規化
    SE-->>TE: 類義語マップ (表記ゆれ)

    TE->>SE: detect_related_terms(candidates, full_text)
    SE->>SE: 包含関係検出 (部分文字列)
    SE->>SE: PMI共起分析 (window=10)
    SE-->>TE: 関連語マップ (包含・共起)

    Note over TE: Phase 6: 軽量LLMフィルタ (略語以外)
    TE->>TE: 上位N%選択 + 全略語
    TE->>LLM: lightweight_llm_filter(candidates)
    LLM-->>TE: フィルタ通過用語

    Note over TE: Phase 7: RAG定義生成
    loop フィルタ通過用語
        TE->>VS: similarity_search(term, k=5)
        VS-->>TE: 関連文書チャンク
        TE->>LLM: generate_definition(term, context)
        LLM-->>TE: 定義文
    end

    Note over TE: Phase 8: 重量LLMフィルタ
    TE->>LLM: technical_term_judgment(term, definition)
    LLM-->>TE: {is_technical: true/false, confidence: 0.9}

    Note over TE: Phase 9: DB保存
    TE->>DB: INSERT INTO jargon_dictionary
    Note right of DB: term, definition,<br/>aliases (表記ゆれ),<br/>related_terms (包含・共起)

    Note over TE: Phase 10: 意味ベース類義語抽出
    TE->>ESS: extract_and_save_semantic_synonyms()
    ESS->>DB: SELECT term, definition, related_terms
    DB-->>ESS: 専門用語リスト
    ESS->>ESS: load_candidate_terms_from_extraction()
    Note right of ESS: term_extraction_debug.json<br/>から候補用語読み込み

    Note over ESS: LLM定義生成 (Option B)
    loop 候補用語
        ESS->>LLM: generate_definition(term)
        LLM-->>ESS: 40-50文字の定義
    end

    ESS->>TCA: extract_semantic_synonyms_hybrid()

    Note over TCA: Embedding生成
    TCA->>LLM: embed_documents(specialized: term + definition)
    LLM-->>TCA: 1536次元ベクトル
    TCA->>LLM: embed_documents(candidates: term + LLM定義)
    LLM-->>TCA: 1536次元ベクトル

    Note over TCA: 次元圧縮・クラスタリング
    TCA->>TCA: UMAP (1536→20次元, cosine)
    TCA->>TCA: HDBSCAN (min_cluster_size=20%, epsilon=0.5)

    Note over TCA: 類義語抽出
    loop 各専門用語
        TCA->>TCA: 同一クラスタ内の用語を検索
        TCA->>TCA: コサイン類似度計算 (threshold=0.50)
        TCA->>TCA: 自分自身を除外
        TCA->>TCA: related_termsに含まれる用語を除外
        TCA->>TCA: 上位10個を類義語として保存
    end

    Note over TCA: LLMクラスタ命名
    TCA->>LLM: name_cluster(terms_in_cluster)
    LLM-->>TCA: クラスタ名 (例: "軸受技術")

    TCA->>DB: UPDATE jargon_dictionary SET aliases, domain
    Note right of DB: aliases: 意味ベース類義語<br/>domain: クラスタ名

    TCA-->>ESS: {synonyms, clusters, cluster_names}
    ESS-->>TE: 類義語辞書
    TE-->>UI: 抽出完了
    UI-->>User: 専門用語一覧表示
</div></code></pre>
<h2 id="%E4%B8%BB%E8%A6%81%E3%83%95%E3%82%A7%E3%83%BC%E3%82%BA%E8%A9%B3%E7%B4%B0">主要フェーズ詳細</h2>
<h3 id="phase-1-%E5%80%99%E8%A3%9C%E6%8A%BD%E5%87%BA">Phase 1: 候補抽出</h3>
<ul>
<li><strong>技術</strong>: Sudachi形態素解析 (C mode)</li>
<li><strong>手法</strong>: N-gram + 名詞連続パターン</li>
<li><strong>出力</strong>: 候補用語 + 頻度</li>
</ul>
<h3 id="phase-2-%E7%B5%B1%E8%A8%88%E3%82%B9%E3%82%B3%E3%82%A2%E8%A8%88%E7%AE%97">Phase 2: 統計スコア計算</h3>
<ul>
<li><strong>TF-IDF</strong>: 文書全体での重要度</li>
<li><strong>C-value</strong>: 複合語としての専門性</li>
<li><strong>2段階スコアリング</strong>:
<ul>
<li>Stage A (seed): C-value重視 → SemReRankのシード選定用</li>
<li>Stage B (final): TF-IDF重視 → 最終スコア計算用</li>
</ul>
</li>
</ul>
<h3 id="phase-3-%E7%95%A5%E8%AA%9E%E3%83%9C%E3%83%BC%E3%83%8A%E3%82%B9">Phase 3: 略語ボーナス</h3>
<ul>
<li><strong>判定パターン</strong>: <code>^[A-Z]{2,5}$</code></li>
<li><strong>ボーナス倍率</strong>: 1.3倍</li>
<li><strong>目的</strong>: 技術文書で重要な略語を優先</li>
</ul>
<h3 id="phase-4-semrerank">Phase 4: SemReRank</h3>
<ul>
<li><strong>グラフ構築</strong>: 用語間の意味的類似度</li>
<li><strong>アルゴリズム</strong>: PageRank</li>
<li><strong>最終スコア</strong>: <code>base_score × (1 + α × pagerank_score)</code></li>
</ul>
<h3 id="phase-5-%E8%A1%A8%E8%A8%98%E3%82%86%E3%82%8C%E3%83%BB%E9%96%A2%E9%80%A3%E8%AA%9E%E6%A4%9C%E5%87%BA">Phase 5: 表記ゆれ・関連語検出</h3>
<h4 id="%E8%A1%A8%E8%A8%98%E3%82%86%E3%82%8C-variants">表記ゆれ (variants)</h4>
<ul>
<li>Levenshtein距離</li>
<li>カタカナ正規化</li>
<li>例: &quot;コンピュータ&quot; ↔ &quot;コンピューター&quot;</li>
</ul>
<h4 id="%E9%96%A2%E9%80%A3%E8%AA%9E-relatedterms">関連語 (related_terms)</h4>
<ul>
<li><strong>包含関係</strong>: 部分文字列検出
<ul>
<li>例: &quot;ILIPS&quot; ⊂ &quot;ILIPS環境価値管理&quot;</li>
</ul>
</li>
<li><strong>PMI共起分析</strong>:
<ul>
<li>ウィンドウサイズ: 10単語</li>
<li>閾値: PMI ≥ 2.0, 共起回数 ≥ 3</li>
</ul>
</li>
</ul>
<h3 id="phase-6-%E8%BB%BD%E9%87%8Fllm%E3%83%95%E3%82%A3%E3%83%AB%E3%82%BF">Phase 6: 軽量LLMフィルタ</h3>
<ul>
<li><strong>対象</strong>: 略語以外の上位N%</li>
<li><strong>目的</strong>: 定義生成コストを削減</li>
<li><strong>略語</strong>: 無条件で次フェーズへ</li>
</ul>
<h3 id="phase-7-rag%E5%AE%9A%E7%BE%A9%E7%94%9F%E6%88%90">Phase 7: RAG定義生成</h3>
<ul>
<li><strong>検索</strong>: ベクトル類似度検索 (k=5)</li>
<li><strong>略語対応</strong>: クエリ拡張 (例: &quot;ETC 略語&quot;)</li>
<li><strong>LLM</strong>: Azure OpenAI GPT-4</li>
<li><strong>出力</strong>: 専門用語の定義文</li>
</ul>
<h3 id="phase-8-%E9%87%8D%E9%87%8Fllm%E3%83%95%E3%82%A3%E3%83%AB%E3%82%BF">Phase 8: 重量LLMフィルタ</h3>
<ul>
<li><strong>判定</strong>: 専門用語 vs 一般用語</li>
<li><strong>出力</strong>: <code>{is_technical: bool, confidence: float}</code></li>
<li><strong>バッチ処理</strong>: 10件/バッチ</li>
</ul>
<h3 id="phase-9-db%E4%BF%9D%E5%AD%98">Phase 9: DB保存</h3>
<pre class="hljs"><code><div><span class="hljs-keyword">INSERT</span> <span class="hljs-keyword">INTO</span> jargon_dictionary (
  term,
  definition,
  aliases,          <span class="hljs-comment">-- 表記ゆれ (Phase 5)</span>
  related_terms     <span class="hljs-comment">-- 包含・共起関係 (Phase 5)</span>
)
</div></code></pre>
<h3 id="phase-10-%E6%84%8F%E5%91%B3%E3%83%99%E3%83%BC%E3%82%B9%E9%A1%9E%E7%BE%A9%E8%AA%9E%E6%8A%BD%E5%87%BA">Phase 10: 意味ベース類義語抽出</h3>
<h4 id="step-1-%E3%83%87%E3%83%BC%E3%82%BF%E8%AA%AD%E3%81%BF%E8%BE%BC%E3%81%BF">Step 1: データ読み込み</h4>
<ul>
<li><strong>専門用語</strong>: DB (<code>term</code>, <code>definition</code>, <code>related_terms</code>)</li>
<li><strong>候補用語</strong>: <code>term_extraction_debug.json</code></li>
</ul>
<h4 id="step-2-llm%E5%AE%9A%E7%BE%A9%E7%94%9F%E6%88%90-option-b">Step 2: LLM定義生成 (Option B)</h4>
<ul>
<li><strong>対象</strong>: 候補用語 (定義なし)</li>
<li><strong>長さ</strong>: 40-50文字</li>
<li><strong>目的</strong>: 候補用語の意味情報を充実化</li>
<li><strong>効果</strong>: F1スコア 83.3%, Recall 93.8%</li>
</ul>
<h4 id="step-3-embedding%E7%94%9F%E6%88%90">Step 3: Embedding生成</h4>
<ul>
<li><strong>専門用語</strong>: <code>&quot;{term}: {definition}&quot;</code></li>
<li><strong>候補用語</strong>: <code>&quot;{term}: {LLM定義}&quot;</code></li>
<li><strong>モデル</strong>: text-embedding-3-small</li>
<li><strong>次元</strong>: 1536</li>
</ul>
<h4 id="step-4-%E6%AC%A1%E5%85%83%E5%9C%A7%E7%B8%AE%E3%83%BB%E3%82%AF%E3%83%A9%E3%82%B9%E3%82%BF%E3%83%AA%E3%83%B3%E3%82%B0">Step 4: 次元圧縮・クラスタリング</h4>
<ul>
<li><strong>UMAP</strong>: 1536次元 → 20次元 (cosine距離)</li>
<li><strong>HDBSCAN</strong>:
<ul>
<li><code>min_cluster_size</code>: データ数の20%</li>
<li><code>cluster_selection_epsilon</code>: 0.5</li>
</ul>
</li>
</ul>
<h4 id="step-5-%E9%A1%9E%E7%BE%A9%E8%AA%9E%E6%8A%BD%E5%87%BA">Step 5: 類義語抽出</h4>
<ul>
<li><strong>同一クラスタ内</strong>で類似度計算</li>
<li><strong>コサイン類似度</strong>: threshold = 0.50</li>
<li><strong>除外ルール</strong>:
<ol>
<li>自分自身</li>
<li><code>related_terms</code>に含まれる用語 (包含・共起関係)</li>
</ol>
</li>
<li><strong>最大数</strong>: 10件/用語</li>
</ul>
<h4 id="step-6-llm%E3%82%AF%E3%83%A9%E3%82%B9%E3%82%BF%E5%91%BD%E5%90%8D">Step 6: LLMクラスタ命名</h4>
<ul>
<li><strong>入力</strong>: クラスタ内の用語リスト</li>
<li><strong>出力</strong>: クラスタ名 (例: &quot;軸受技術&quot;, &quot;環境・持続可能技術&quot;)</li>
</ul>
<h4 id="step-7-db%E6%9B%B4%E6%96%B0">Step 7: DB更新</h4>
<pre class="hljs"><code><div><span class="hljs-keyword">UPDATE</span> jargon_dictionary <span class="hljs-keyword">SET</span>
  aliases = [...],    <span class="hljs-comment">-- 意味ベース類義語で上書き</span>
  <span class="hljs-keyword">domain</span> = <span class="hljs-string">'...'</span>      <span class="hljs-comment">-- クラスタ名</span>
</div></code></pre>
<h2 id="%E3%83%87%E3%83%BC%E3%82%BF%E3%83%95%E3%83%AD%E3%83%BC">データフロー</h2>
<pre class="hljs"><code><div>PDFファイル
  ↓
候補用語 (Phase 1-4)
  ↓
表記ゆれ検出 (Phase 5) → aliases (一時)
  ↓
関連語検出 (Phase 5) → related_terms
  ↓
LLMフィルタ + 定義生成 (Phase 6-8)
  ↓
DB保存 (Phase 9)
  term, definition, aliases (表記ゆれ), related_terms
  ↓
意味ベース類義語抽出 (Phase 10)
  ↓
DB更新
  aliases ← 意味ベース類義語 (上書き)
  domain ← クラスタ名
</div></code></pre>
<h2 id="%E9%87%8D%E8%A6%81%E3%81%AA%E6%B3%A8%E6%84%8F%E7%82%B9">重要な注意点</h2>
<h3 id="aliases-%E3%83%95%E3%82%A3%E3%83%BC%E3%83%AB%E3%83%89%E3%81%AE2%E6%AE%B5%E9%9A%8E%E6%9B%B4%E6%96%B0">aliases フィールドの2段階更新</h3>
<ol>
<li><strong>Phase 9</strong>: 表記ゆれ (Levenshtein距離ベース)</li>
<li><strong>Phase 10</strong>: 意味ベース類義語 (HDBSCAN + LLM) で<strong>上書き</strong></li>
</ol>
<h3 id="relatedterms-vs-aliases-%E3%81%AE%E9%81%95%E3%81%84">related_terms vs aliases の違い</h3>
<ul>
<li>
<p><strong>related_terms</strong> (包含・共起):</p>
<ul>
<li>包含関係: &quot;ILIPS&quot; ⊂ &quot;ILIPS環境価値管理&quot;</li>
<li>PMI共起: 同じ文脈で頻繁に出現</li>
<li><strong>Phase 10で除外</strong>: 類義語に含めない</li>
</ul>
</li>
<li>
<p><strong>aliases</strong> (意味ベース類義語):</p>
<ul>
<li>同一クラスタ内の意味的に近い用語</li>
<li>コサイン類似度 ≥ 0.50</li>
<li><code>related_terms</code>に含まれない用語のみ</li>
</ul>
</li>
</ul>
<h3 id="%E6%9C%80%E9%81%A9%E5%8C%96%E6%B8%88%E3%81%BF%E3%83%91%E3%83%A9%E3%83%A1%E3%83%BC%E3%82%BF">最適化済みパラメータ</h3>
<ul>
<li><strong>類似度閾値</strong>: 0.50 (F1=83.3%, Recall=93.8%, Precision=75.0%)</li>
<li><strong>HDBSCAN epsilon</strong>: 0.5</li>
<li><strong>最大類義語数</strong>: 10件/用語</li>
</ul>
<h2 id="%E3%83%95%E3%82%A1%E3%82%A4%E3%83%AB%E6%A7%8B%E6%88%90">ファイル構成</h2>
<ul>
<li><strong>src/rag/term_extraction.py</strong>: Phase 1-9のメインロジック</li>
<li><strong>src/rag/advanced_term_extraction.py</strong>: StatisticalExtractor実装</li>
<li><strong>src/scripts/extract_semantic_synonyms.py</strong>: Phase 10のエントリポイント</li>
<li><strong>src/scripts/term_clustering_analyzer.py</strong>: HDBSCAN + UMAP実装</li>
<li><strong>output/term_extraction_debug.json</strong>: 候補用語の中間ファイル</li>
</ul>

</body>
</html>
