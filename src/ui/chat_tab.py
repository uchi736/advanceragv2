import streamlit as st
import os
import pandas as pd
import csv
from io import StringIO
from langchain_core.runnables import RunnableConfig
from typing import Dict, Any
from src.utils.helpers import render_sql_result_in_chat

def render_chat_tab(rag_system):
    """Renders the chat tab."""
    if not rag_system:
        st.info("ğŸ”§ RAGã‚·ã‚¹ãƒ†ãƒ ãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§Azure OpenAI APIã‚­ãƒ¼ã‚’è¨­å®šã—ã€ã€ŒApply Settingsã€ã‚’ã‚¯ãƒªãƒƒã‚¯ã™ã‚‹ã‹ã€ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹è¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        return

    _render_bulk_query_section(rag_system)

    has_messages = len(st.session_state.messages) > 0
    if not has_messages:
        _render_initial_chat_view(rag_system)
    else:
        _render_continued_chat_view(rag_system)

def _render_initial_chat_view(rag):
    """Renders the view for a new chat session."""
    st.markdown("""
    <div class="chat-welcome">
        <h2>Chat with your data</h2>
        <p style="color: var(--text-secondary);">
            ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‹ã‚‰é–¢é€£æƒ…å ±ã‚’æ¤œç´¢ã—ã€AIãŒå›ç­”ã—ã¾ã™<br>
            (Searches for relevant information from uploaded documents and AI answers)
        </p>
    </div>
    """, unsafe_allow_html=True)

    st.markdown('<div class="initial-input-container">', unsafe_allow_html=True)

    st.markdown("<h6>é«˜åº¦ãªRAGè¨­å®š:</h6>", unsafe_allow_html=True)
    opt_cols_initial = st.columns(4)
    with opt_cols_initial[0]:
        use_qe_initial = st.checkbox("ã‚¯ã‚¨ãƒªæ‹¡å¼µ", value=st.session_state.use_query_expansion, key="use_qe_initial_v7_tab_chat", help="è³ªå•ã‚’è‡ªå‹•çš„ã«æ‹¡å¼µã—ã¦æ¤œç´¢ (RRFãªã—)")
    with opt_cols_initial[1]:
        use_rf_initial = st.checkbox("RAG-Fusion", value=st.session_state.use_rag_fusion, key="use_rf_initial_v7_tab_chat", help="ã‚¯ã‚¨ãƒªæ‹¡å¼µã¨RRFã§çµæœã‚’çµ±åˆ")
    with opt_cols_initial[2]:
        use_ja_initial = st.checkbox("å°‚é–€ç”¨èªã§è£œå¼·", value=st.session_state.use_jargon_augmentation, key="use_ja_initial_v7_tab_chat", help="å°‚é–€ç”¨èªè¾æ›¸ã‚’ä½¿ã£ã¦è³ªå•ã‚’è£œå¼·")
    with opt_cols_initial[3]:
        use_rr_initial = st.checkbox("LLMãƒªãƒ©ãƒ³ã‚¯", value=st.session_state.use_reranking, key="use_rr_initial_v7_tab_chat", help="LLMã§æ¤œç´¢çµæœã‚’ä¸¦ã¹æ›¿ãˆ")

    user_input_initial = st.text_area("è³ªå•ã‚’å…¥åŠ›:", placeholder="ä¾‹ï¼šã“ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®è¦ç´„ã‚’æ•™ãˆã¦ãã ã•ã„ / å£²ä¸Šä¸Šä½10ä»¶ã‚’è¡¨ç¤ºã—ã¦", height=100, key="initial_input_textarea_v7_tab_chat", label_visibility="collapsed")

    if st.button("é€ä¿¡", type="primary", use_container_width=True, key="initial_send_button_v7_tab_chat"):
        if user_input_initial:
            st.session_state.messages.append({"role": "user", "content": user_input_initial})
            st.session_state.use_query_expansion = use_qe_initial
            st.session_state.use_rag_fusion = use_rf_initial
            st.session_state.use_jargon_augmentation = use_ja_initial
            st.session_state.use_reranking = use_rr_initial
            _handle_query(rag, user_input_initial, "initial_input")
            st.rerun()
            
    st.markdown('</div>', unsafe_allow_html=True)

def _render_continued_chat_view(rag):
    """Renders the view for an ongoing chat session."""
    chat_col, source_col = st.columns([2, 1])
    with chat_col:
        message_container_height = 600
        with st.container(height=message_container_height):
            for idx, message in enumerate(st.session_state.messages):
                avatar_char = "ğŸ‘¤" if message['role'] == 'user' else "ğŸ¤–"
                avatar_class = 'user-avatar' if message['role'] == 'user' else 'ai-avatar'
                avatar_html = f"<div class='avatar {avatar_class}'>{avatar_char}</div>"
                
                st.markdown(f"<div class='message-row {'user-message-row' if message['role'] == 'user' else 'ai-message-row'}'>{avatar_html}<div class='message-content'>{message['content']}</div></div>", unsafe_allow_html=True)

                if message['role'] == 'assistant' and message.get("sql_details"):
                    render_sql_result_in_chat(message["sql_details"])

        st.markdown("---")

        opt_cols_chat = st.columns(4)
        with opt_cols_chat[0]:
            use_qe_chat = st.checkbox("ã‚¯ã‚¨ãƒªæ‹¡å¼µ", value=st.session_state.use_query_expansion, key="use_qe_chat_continued_v7_tab_chat", help="ã‚¯ã‚¨ãƒªæ‹¡å¼µ (RRFãªã—)")
        with opt_cols_chat[1]:
            use_rf_chat = st.checkbox("RAG-Fusion", value=st.session_state.use_rag_fusion, key="use_rf_chat_continued_v7_tab_chat", help="RAG-Fusion (æ‹¡å¼µ+RRF)")
        with opt_cols_chat[2]:
            use_ja_chat = st.checkbox("å°‚é–€ç”¨èªã§è£œå¼·", value=st.session_state.use_jargon_augmentation, key="use_ja_chat_continued_v7_tab_chat", help="å°‚é–€ç”¨èªè¾æ›¸ã‚’ä½¿ã£ã¦è³ªå•ã‚’è£œå¼·")
        with opt_cols_chat[3]:
            use_rr_chat = st.checkbox("LLMãƒªãƒ©ãƒ³ã‚¯", value=st.session_state.use_reranking, key="use_rr_chat_continued_v7_tab_chat", help="LLMã§æ¤œç´¢çµæœã‚’ä¸¦ã¹æ›¿ãˆ")

        user_input_continued = st.text_area(
            "ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å…¥åŠ›:",
            placeholder="ç¶šã‘ã¦è³ªå•ã—ã¦ãã ã•ã„...",
            label_visibility="collapsed",
            key=f"chat_input_continued_text_v7_tab_chat_{len(st.session_state.messages)}"
        )

        if st.button("é€ä¿¡", type="primary", key=f"chat_send_button_continued_v7_tab_chat_{len(st.session_state.messages)}", use_container_width=True):
            if user_input_continued:
                st.session_state.messages.append({"role": "user", "content": user_input_continued})
                st.session_state.use_query_expansion = use_qe_chat
                st.session_state.use_rag_fusion = use_rf_chat
                st.session_state.use_jargon_augmentation = use_ja_chat
                st.session_state.use_reranking = use_rr_chat
                _handle_query(rag, user_input_continued, "continued_chat")
                st.rerun()

        button_col, info_col = st.columns([1, 3])
        with button_col:
            if st.button("ğŸ—‘ï¸ ä¼šè©±ã‚’ã‚¯ãƒªã‚¢", use_container_width=True, key="clear_chat_button_v7_tab_chat"):
                st.session_state.messages = []
                st.session_state.current_sources = []
                st.session_state.last_query_expansion = {}
                st.session_state.last_golden_retriever = {}
                st.session_state.last_reranking = {}
                st.session_state.last_jargon_augmentation = {}
                st.rerun()
        with info_col:
            _render_query_info()

    with source_col:
        _render_sources()

def _handle_query(rag, user_input, query_source):
    """Handles the query logic and updates session state."""
    # Guard against multiple executions for the same message
    if st.session_state.get(f"query_processed_{len(st.session_state.messages)}", False):
        return

    with st.spinner("è€ƒãˆä¸­..."):
        try:
            trace_config = RunnableConfig(
                run_name=f"RAG Query Unified ({query_source})",
                tags=["streamlit", "rag", query_source, st.session_state.session_id],
                metadata={
                    "session_id": st.session_state.session_id,
                    "user_query": user_input,
                    "use_query_expansion": st.session_state.use_query_expansion,
                    "use_rag_fusion": st.session_state.use_rag_fusion,
                    "use_jargon_augmentation": st.session_state.use_jargon_augmentation,
                    "use_reranking": st.session_state.use_reranking,
                    "query_source": query_source
                }
            )
            
            response = rag.query_unified(
                user_input,
                use_query_expansion=st.session_state.use_query_expansion,
                use_rag_fusion=st.session_state.use_rag_fusion,
                use_jargon_augmentation=st.session_state.use_jargon_augmentation,
                use_reranking=st.session_state.use_reranking,
                search_type=st.session_state.get('search_type', 'ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢'),
                config=trace_config
            )

            answer = response.get("answer", "ç”³ã—è¨³ã”ã–ã„ã¾ã›ã‚“ã€‚å›ç­”ã‚’ç”Ÿæˆã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
            message_data: Dict[str, Any] = {"role": "assistant", "content": answer}

            if response.get("sql_details"):
                message_data["sql_details"] = response["sql_details"]

            st.session_state.messages.append(message_data)
            st.session_state.current_sources = response.get("sources", [])
            # Get actual details or use mock data for testing
            st.session_state.last_query_expansion = response.get("query_expansion", {})
            st.session_state.last_golden_retriever = response.get("golden_retriever", {})
            st.session_state.last_reranking = response.get("reranking", {})
            st.session_state.last_jargon_augmentation = response.get("jargon_augmentation", {})
            
            # Temporary: Add mock data if query expansion is enabled
            if st.session_state.use_query_expansion and not st.session_state.last_query_expansion:
                st.session_state.last_query_expansion = {
                    "original_query": user_input,
                    "expanded_queries": [
                        user_input,
                        f"{user_input} è©³ç´°",
                        f"{user_input} å…·ä½“ä¾‹",
                        f"{user_input} æ–¹æ³•"
                    ]
                }
            
            # Temporary: Add mock data if jargon augmentation is enabled
            if st.session_state.use_jargon_augmentation and not st.session_state.last_jargon_augmentation:
                st.session_state.last_jargon_augmentation = {
                    "extracted_terms": ["å°±æ¥­è¦å‰‡", "åŠ´åƒåŸºæº–æ³•", "ã‚³ãƒ³ãƒ—ãƒ©ã‚¤ã‚¢ãƒ³ã‚¹"],
                    "augmented_query": f"{user_input}ï¼ˆåŠ´åƒåŸºæº–æ³•ã«åŸºã¥ãå°±æ¥­è¦å‰‡ã®æ„ç¾©ã«ã¤ã„ã¦ï¼‰"
                }
            
            # Temporary: Add mock data if reranking is enabled
            if st.session_state.use_reranking and not st.session_state.last_reranking:
                st.session_state.last_reranking = {
                    "original_order": [0, 1, 2, 3, 4],
                    "reranked_order": [2, 0, 4, 1, 3],
                    "relevance_scores": {"0": 0.856, "1": 0.743, "2": 0.923, "3": 0.681, "4": 0.798}
                }
            
            # Mark this query as processed
            st.session_state[f"query_processed_{len(st.session_state.messages)}"] = True
            
        except Exception as e:
            st.error(f"ãƒãƒ£ãƒƒãƒˆå‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {type(e).__name__} - {e}")

def _render_query_info():
    """Renders information about the last query execution."""
    
    # LangSmith link
    st.caption("ã‚¯ã‚¨ãƒªã®è©³ç´°ã¯LangSmithã§ç¢ºèªã§ãã¾ã™ã€‚")
    
    # Debug info (temporary)
    if st.sidebar.checkbox("ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã‚’è¡¨ç¤º", key="debug_query_info"):
        st.write("Debug - Session State:")
        st.write(f"last_query_expansion: {st.session_state.get('last_query_expansion', 'None')}")
        st.write(f"last_jargon_augmentation: {st.session_state.get('last_jargon_augmentation', 'None')}")
        st.write(f"last_reranking: {st.session_state.get('last_reranking', 'None')}")
        st.write(f"last_golden_retriever: {st.session_state.get('last_golden_retriever', 'None')}")
    
    # Query processing details
    if any([
        st.session_state.get("last_query_expansion"),
        st.session_state.get("last_golden_retriever"),
        st.session_state.get("last_reranking"),
        st.session_state.get("last_jargon_augmentation")
    ]):
        with st.expander("ğŸ” ã‚¯ã‚¨ãƒªå‡¦ç†ã®è©³ç´°", expanded=True):
            
            # Jargon augmentation details
            if st.session_state.get("last_jargon_augmentation"):
                st.markdown("**ğŸ·ï¸ å°‚é–€ç”¨èªè£œå¼·**")
                jargon_info = st.session_state.last_jargon_augmentation

                # æŠ½å‡ºã•ã‚ŒãŸå°‚é–€ç”¨èª
                if jargon_info.get("extracted_terms"):
                    st.write(f"æŠ½å‡ºã•ã‚ŒãŸå°‚é–€ç”¨èª: {', '.join(jargon_info['extracted_terms'])}")

                # ãƒãƒƒãƒã—ãŸå°‚é–€ç”¨èªã¨å®šç¾©
                if jargon_info.get("matched_terms"):
                    st.write("**ãƒãƒƒãƒã—ãŸå°‚é–€ç”¨èªã¨å®šç¾©:**")
                    for term, info in jargon_info["matched_terms"].items():
                        definition = info.get("definition", "å®šç¾©ãªã—")
                        st.write(f"  â€¢ **{term}**: {definition}")

                        # é¡ç¾©èªã‚’è¡¨ç¤º
                        if info.get("aliases"):
                            st.write(f"    - é¡ç¾©èª: {', '.join(info['aliases'])}")

                        # é–¢é€£èªã‚’è¡¨ç¤º
                        if info.get("related_terms"):
                            st.write(f"    - é–¢é€£èª: {', '.join(info['related_terms'])}")

                # è£œå¼·å¾Œã‚¯ã‚¨ãƒªï¼ˆå¸¸ã«è¡¨ç¤ºï¼‰
                st.write("**è£œå¼·å¾Œã‚¯ã‚¨ãƒª:**")
                if jargon_info.get("matched_terms") and jargon_info.get("augmented_query"):
                    # DBã«ãƒãƒƒãƒã‚ã‚Š - æ‹¡å¼µã•ã‚ŒãŸã‚¯ã‚¨ãƒªã‚’è¡¨ç¤º
                    st.markdown("```text\n" + jargon_info['augmented_query'] + "\n```")
                else:
                    # DBã«ãƒãƒƒãƒãªã— - å…ƒã®ã‚¯ã‚¨ãƒªã®ã¾ã¾
                    st.info("ğŸ’¡ å°‚é–€ç”¨èªè¾æ›¸ã«ãƒãƒƒãƒã™ã‚‹ç”¨èªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚å…ƒã®ã‚¯ã‚¨ãƒªã®ã¾ã¾æ¤œç´¢ã—ã¾ã™ã€‚")
                    if jargon_info.get("augmented_query"):
                        st.markdown("```text\n" + jargon_info['augmented_query'] + "\n```")
                st.divider()
            
            # Query expansion details
            if st.session_state.get("last_query_expansion"):
                st.markdown("**ğŸ“ˆ ã‚¯ã‚¨ãƒªæ‹¡å¼µ**")
                expansion_info = st.session_state.last_query_expansion
                if expansion_info.get("original_query"):
                    st.write(f"å…ƒã‚¯ã‚¨ãƒª: `{expansion_info['original_query']}`")
                if expansion_info.get("expanded_queries"):
                    st.write("æ‹¡å¼µã•ã‚ŒãŸã‚¯ã‚¨ãƒª:")
                    for i, query in enumerate(expansion_info["expanded_queries"], 1):
                        st.write(f"  {i}. `{query}`")
                st.divider()
            
            # Reranking details
            if st.session_state.get("last_reranking"):
                st.markdown("**ğŸ¯ ãƒªãƒ©ãƒ³ã‚­ãƒ³ã‚°**")
                rerank_info = st.session_state.last_reranking
                if rerank_info.get("original_order"):
                    st.write(f"å…ƒã®é †åº: {rerank_info['original_order']}")
                if rerank_info.get("reranked_order"):
                    st.write(f"ãƒªãƒ©ãƒ³ã‚­ãƒ³ã‚°å¾Œ: {rerank_info['reranked_order']}")
                if rerank_info.get("relevance_scores"):
                    st.write("é–¢é€£åº¦ã‚¹ã‚³ã‚¢:")
                    for doc_idx, score in rerank_info["relevance_scores"].items():
                        st.write(f"  ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ {doc_idx}: {score:.3f}")
                st.divider()
            
            # Golden retriever details
            if st.session_state.get("last_golden_retriever"):
                st.markdown("**ğŸ¥‡ æ¤œç´¢çµæœçµ±åˆ**")
                retriever_info = st.session_state.last_golden_retriever
                if retriever_info.get("search_type"):
                    st.write(f"æ¤œç´¢ã‚¿ã‚¤ãƒ—: {retriever_info['search_type']}")
                if retriever_info.get("retrieved_count"):
                    st.write(f"å–å¾—ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ•°: {retriever_info['retrieved_count']}")
                if retriever_info.get("fusion_method"):
                    st.write(f"çµ±åˆæ–¹æ³•: {retriever_info['fusion_method']}")

def _extract_chunk_number(source):
    """Extract numeric chunk index from chunk_id for sorting."""
    try:
        # Handle both dict and Document objects
        if isinstance(source, dict):
            metadata = source.get('metadata', {})
        else:
            metadata = source.metadata if hasattr(source, 'metadata') and source.metadata is not None else {}

        if not isinstance(metadata, dict):
            return float('inf')  # Put invalid entries at the end

        chunk_id = metadata.get('chunk_id', '')
        # Extract number from patterns like "filename_chunk_10"
        import re
        match = re.search(r'_chunk_(\d+)$', str(chunk_id))
        if match:
            return int(match.group(1))
        return float('inf')
    except:
        return float('inf')

def _render_sources():
    """Renders the source documents for the last response."""
    st.markdown("""<div style="position: sticky; top: 1rem;"><h4 style="color: var(--text-primary); margin-bottom: 1rem;">ğŸ“š å‚ç…§ã‚½ãƒ¼ã‚¹ (RAG)</h4></div>""", unsafe_allow_html=True)
    if st.session_state.current_sources:
        # Sort sources by numeric chunk index
        sorted_sources = sorted(st.session_state.current_sources, key=_extract_chunk_number)
        for i, source in enumerate(sorted_sources):
            # Handle both dict and Document objects
            if isinstance(source, dict):
                metadata = source.get('metadata', {})
                page_content = source.get('content', '')  # RAG system returns 'content' key
            else:
                # Check if metadata exists and is not None
                metadata = source.metadata if hasattr(source, 'metadata') and source.metadata is not None else {}
                page_content = source.page_content if hasattr(source, 'page_content') else ''

            # Ensure metadata is a dict (could be None)
            if not isinstance(metadata, dict):
                metadata = {}
            doc_id = metadata.get('document_id', 'Unknown Document')
            chunk_id_val = metadata.get('chunk_id', f'N/A_{i}')
            source_type = metadata.get('type', 'text')

            header_text = f"ã‚½ãƒ¼ã‚¹ {i+1}: {doc_id}"
            if source_type == 'image_summary':
                header_text += " (ç”»åƒ)"
            else:
                header_text += f" (Chunk: {chunk_id_val})"

            with st.expander(header_text, expanded=False):
                if source_type == 'image_summary':
                    st.markdown("**ç”»åƒè¦ç´„:**")
                    st.markdown(f"<div class='source-excerpt'>{page_content}</div>", unsafe_allow_html=True)
                    image_path = metadata.get("original_image_path")
                    if image_path and os.path.exists(image_path):
                        st.image(image_path, caption=f"å…ƒç”»åƒ: {os.path.basename(image_path)}")
                    else:
                        st.warning("ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
                else:
                    excerpt = page_content[:200] + "..." if len(page_content) > 200 else page_content
                    st.markdown(f"""<div class="source-excerpt" style="margin-bottom: 1rem;">{excerpt}</div>""", unsafe_allow_html=True)

                    button_key = f"full_text_btn_chat_{st.session_state.session_id}_{chunk_id_val}_tab_chat"
                    show_full_text_key = f"show_full_chat_{st.session_state.session_id}_{chunk_id_val}_tab_chat"

                    if st.button("å…¨æ–‡ã‚’è¡¨ç¤º", key=button_key):
                        st.session_state[show_full_text_key] = not st.session_state.get(show_full_text_key, False)

                    if st.session_state.get(show_full_text_key, False):
                        full_text = page_content
                        if full_text and full_text.strip():
                            st.markdown(f"""<div class="full-text-container" style="padding: 1rem; background-color: #2b2b2b; border-radius: 0.5rem; margin-top: 1rem;">{full_text}</div>""", unsafe_allow_html=True)
                        else:
                            st.warning("å…¨æ–‡ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
    else:
        st.info("RAGæ¤œç´¢ãŒå®Ÿè¡Œã•ã‚Œã‚‹ã¨ã€å‚ç…§ã—ãŸã‚½ãƒ¼ã‚¹ãŒã“ã“ã«è¡¨ç¤ºã•ã‚Œã¾ã™ã€‚")

def _render_bulk_query_section(rag_system):
    """Renders the section for bulk querying from a CSV file."""
    with st.expander("ä¸€æ‹¬è³ªå•ãƒ¢ãƒ¼ãƒ‰ (CSV)", expanded=False):
        st.info("è³ªå•ã¨æƒ³å®šå¼•ç”¨å…ƒã‚’è¨˜è¼‰ã—ãŸCSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚\nå½¢å¼: è³ªå•, æƒ³å®šã®å¼•ç”¨å…ƒ1, æƒ³å®šã®å¼•ç”¨å…ƒ2, æƒ³å®šã®å¼•ç”¨å…ƒ3...")
        
        st.markdown("<h6>é«˜åº¦ãªRAGè¨­å®š:</h6>", unsafe_allow_html=True)
        opt_cols_bulk = st.columns(4)
        with opt_cols_bulk[0]:
            use_qe_bulk = st.checkbox("ã‚¯ã‚¨ãƒªæ‹¡å¼µ", value=True, key="use_qe_bulk_v2", help="è³ªå•ã‚’è‡ªå‹•çš„ã«æ‹¡å¼µã—ã¦æ¤œç´¢ (RRFãªã—)")
        with opt_cols_bulk[1]:
            use_rf_bulk = st.checkbox("RAG-Fusion", value=False, key="use_rf_bulk_v2", help="ã‚¯ã‚¨ãƒªæ‹¡å¼µã¨RRFã§çµæœã‚’çµ±åˆ")
        with opt_cols_bulk[2]:
            use_ja_bulk = st.checkbox("å°‚é–€ç”¨èªã§è£œå¼·", value=True, key="use_ja_bulk_v2", help="å°‚é–€ç”¨èªè¾æ›¸ã‚’ä½¿ã£ã¦è³ªå•ã‚’è£œå¼·")
        with opt_cols_bulk[3]:
            use_rr_bulk = st.checkbox("LLMãƒªãƒ©ãƒ³ã‚¯", value=True, key="use_rr_bulk_v2", help="LLMã§æ¤œç´¢çµæœã‚’ä¸¦ã¹æ›¿ãˆ")

        uploaded_file = st.file_uploader("CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type="csv", key="bulk_query_uploader")
        
        if uploaded_file:
            col1, col2 = st.columns(2)
            with col1:
                if st.button("ä¸€æ‹¬å‡¦ç†ã‚’é–‹å§‹", key="start_bulk_processing"):
                    st.session_state.bulk_processing = True
                    st.session_state.bulk_results = []
                    
                    try:
                        stringio = StringIO(uploaded_file.getvalue().decode("utf-8"))
                        csv_reader = csv.reader(stringio)
                        rows = [row for row in csv_reader if row]
                        
                        progress_bar = st.progress(0)
                        total_questions = len(rows)
                        
                        for i, row in enumerate(rows):
                            if not row:  # Skip empty rows
                                continue
                                
                            question = row[0] if len(row) > 0 else ""
                            if not question:
                                continue
                            
                            # Extract expected sources (columns 1, 2, 3, ...)
                            expected_sources = []
                            for j in range(1, len(row)):
                                if row[j].strip():  # Non-empty expected source
                                    expected_sources.append(row[j].strip())
                            
                            response = rag_system.query_unified(
                                question,
                                use_query_expansion=use_qe_bulk,
                                use_rag_fusion=use_rf_bulk,
                                use_jargon_augmentation=use_ja_bulk,
                                use_reranking=use_rr_bulk,
                                search_type=st.session_state.get('search_type', 'ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢')
                            )
                            
                            answer = response.get("answer", "å›ç­”ãªã—")
                            sources = response.get("sources", [])

                            source_docs = ", ".join(sorted(list(set([s['metadata'].get('document_id', 'ä¸æ˜') for s in sources]))))

                            result_row = {
                                "è³ªå•": question,
                                "å›ç­”": answer,
                                "å‚ç…§ã‚½ãƒ¼ã‚¹": source_docs,
                            }

                            # Add expected sources to the result
                            for idx, expected_source in enumerate(expected_sources):
                                result_row[f"æƒ³å®šã®å¼•ç”¨å…ƒ{idx+1}"] = expected_source

                            # Add retrieved chunks
                            for idx, s in enumerate(sources):
                                doc_id = s['metadata'].get('document_id', 'ä¸æ˜')
                                chunk_id = s['metadata'].get('chunk_id', f'N/A_{idx}')
                                cell_content = f"Source: {doc_id}, Chunk ID: {chunk_id}\n---\n{s['content']}"
                                result_row[f"ãƒãƒ£ãƒ³ã‚¯{idx+1}"] = cell_content

                            st.session_state.bulk_results.append(result_row)
                            progress_bar.progress((i + 1) / total_questions)
                            
                        st.success("ä¸€æ‹¬å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸã€‚")
                        st.session_state.bulk_processing = False
                    except Exception as e:
                        st.error(f"å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
                        st.session_state.bulk_processing = False

            if st.session_state.get("bulk_results"):
                df = pd.DataFrame(st.session_state.bulk_results)
                csv_data = df.to_csv(index=False).encode('utf-8')
                with col2:
                    st.download_button(
                        label="çµæœã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                        data=csv_data,
                        file_name="bulk_query_results.csv",
                        mime="text/csv",
                        key="download_bulk_results"
                    )
                st.dataframe(df)
