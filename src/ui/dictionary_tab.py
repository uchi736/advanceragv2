import streamlit as st
import pandas as pd
from datetime import datetime
from src.rag.term_extraction import JargonDictionaryManager
from src.rag.config import Config
from src.utils.helpers import render_term_card

@st.cache_data(ttl=60, show_spinner=False)
def get_all_terms_cached(_jargon_manager):
    return pd.DataFrame(_jargon_manager.get_all_terms())

def render_dictionary_tab(rag_system):
    """Renders the dictionary tab."""
    st.markdown("### ğŸ“– å°‚é–€ç”¨èªè¾æ›¸")
    st.caption("ç™»éŒ²ã•ã‚ŒãŸå°‚é–€ç”¨èªãƒ»é¡ç¾©èªã‚’æ¤œç´¢ãƒ»ç¢ºèªãƒ»å‰Šé™¤ã§ãã¾ã™ã€‚")

    if not rag_system:
        st.warning("âš ï¸ RAGã‚·ã‚¹ãƒ†ãƒ ãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        return

    # Check if jargon manager is available
    if not hasattr(rag_system, 'jargon_manager') or rag_system.jargon_manager is None:
        st.warning("âš ï¸ å°‚é–€ç”¨èªè¾æ›¸æ©Ÿèƒ½ã¯ç¾åœ¨åˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚")
        return

    jargon_manager = rag_system.jargon_manager

    # Manual term registration form
    with st.expander("â• æ–°ã—ã„ç”¨èªã‚’æ‰‹å‹•ã§ç™»éŒ²ã™ã‚‹"):
        with st.form(key="add_term_form"):
            new_term = st.text_input("ç”¨èª*", help="ç™»éŒ²ã™ã‚‹å°‚é–€ç”¨èª")
            new_definition = st.text_area("å®šç¾©*", help="ç”¨èªã®å®šç¾©ã‚„èª¬æ˜")
            new_domain = st.text_input("åˆ†é‡", help="é–¢é€£ã™ã‚‹æŠ€è¡“åˆ†é‡ã‚„ãƒ‰ãƒ¡ã‚¤ãƒ³")
            new_aliases = st.text_input("é¡ç¾©èª (ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Š)", help="ä¾‹: RAG, æ¤œç´¢æ‹¡å¼µç”Ÿæˆ")
            new_related_terms = st.text_input("é–¢é€£èª (ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Š)", help="ä¾‹: LLM, Vector Search")
            
            submitted = st.form_submit_button("ç™»éŒ²")
            if submitted:
                if not new_term or not new_definition:
                    st.error("ã€Œç”¨èªã€ã¨ã€Œå®šç¾©ã€ã¯å¿…é ˆé …ç›®ã§ã™ã€‚")
                else:
                    aliases_list = [alias.strip() for alias in new_aliases.split(',') if alias.strip()]
                    related_list = [rel.strip() for rel in new_related_terms.split(',') if rel.strip()]
                    
                    if jargon_manager.add_term(
                        term=new_term,
                        definition=new_definition,
                        domain=new_domain,
                        aliases=aliases_list,
                        related_terms=related_list
                    ):
                        st.success(f"ç”¨èªã€Œ{new_term}ã€ã‚’ç™»éŒ²ã—ã¾ã—ãŸã€‚")
                        get_all_terms_cached.clear()
                        st.rerun()
                    else:
                        st.error(f"ç”¨èªã€Œ{new_term}ã€ã®ç™»éŒ²ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
    
    st.markdown("---")

    # Search and refresh buttons
    col1, col2 = st.columns([3, 1])
    with col1:
        search_keyword = st.text_input(
            "ğŸ” ç”¨èªæ¤œç´¢",
            placeholder="æ¤œç´¢ã—ãŸã„ç”¨èªã‚’å…¥åŠ›ã—ã¦ãã ã•ã„...",
            key="term_search_input"
        )
    with col2:
        st.markdown("<br>", unsafe_allow_html=True)
        if st.button("ğŸ”„ æ›´æ–°", key="refresh_terms", use_container_width=True):
            get_all_terms_cached.clear()
            st.rerun()

    # Load term data
    with st.spinner("ç”¨èªè¾æ›¸ã‚’èª­ã¿è¾¼ã¿ä¸­..."):
        all_terms_df = get_all_terms_cached(jargon_manager)

    if all_terms_df.empty:
        st.info("ã¾ã ç”¨èªãŒç™»éŒ²ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®ã€ŒğŸ“š ç”¨èªè¾æ›¸ç”Ÿæˆã€ã‹ã‚‰ç”¨èªã‚’æŠ½å‡ºã—ã¦ãã ã•ã„ã€‚")
        return

    # Filter terms
    if search_keyword:
        terms_df = all_terms_df[
            all_terms_df['term'].str.contains(search_keyword, case=False) |
            all_terms_df['definition'].str.contains(search_keyword, case=False) |
            all_terms_df['aliases'].apply(lambda x: any(search_keyword.lower() in str(s).lower() for s in x) if x else False)
        ]
    else:
        terms_df = all_terms_df

    if terms_df.empty:
        st.info(f"ã€Œ{search_keyword}ã€ã«è©²å½“ã™ã‚‹ç”¨èªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
        return

    # Statistics
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("ç™»éŒ²ç”¨èªæ•°", f"{len(terms_df):,}")
    with col2:
        total_synonyms = sum(len(syn_list) if syn_list else 0 for syn_list in terms_df['aliases'])
        st.metric("é¡ç¾©èªç·æ•°", f"{total_synonyms:,}")
    with col3:
        avg_confidence = terms_df['confidence_score'].mean() if 'confidence_score' in terms_df and not terms_df['confidence_score'].isnull().all() else 0.0
        st.metric("å¹³å‡ä¿¡é ¼åº¦", f"{avg_confidence:.2f}")

    st.markdown("---")

    # View mode selection
    view_mode = st.radio(
        "è¡¨ç¤ºå½¢å¼",
        ["ã‚«ãƒ¼ãƒ‰å½¢å¼", "ãƒ†ãƒ¼ãƒ–ãƒ«å½¢å¼"],
        horizontal=True,
        key="dict_view_mode"
    )

    if view_mode == "ã‚«ãƒ¼ãƒ‰å½¢å¼":
        for idx, row in terms_df.iterrows():
            render_term_card(row)
            # Use term as unique key instead of id (which doesn't exist in ChromaDB)
            delete_key = f"delete_card_{row['term']}_{idx}" if 'id' not in row else f"delete_card_{row['id']}"
            if st.button("å‰Šé™¤", key=delete_key, use_container_width=True):
                deleted, errors = rag_system.delete_jargon_terms([row['term']])
                if deleted:
                    st.success(f"ç”¨èªã€Œ{row['term']}ã€ã‚’å‰Šé™¤ã—ã¾ã—ãŸã€‚")
                    get_all_terms_cached.clear()
                    st.rerun()
                else:
                    st.error(f"ç”¨èªã€Œ{row['term']}ã€ã®å‰Šé™¤ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")

    else: # ãƒ†ãƒ¼ãƒ–ãƒ«å½¢å¼
        display_df = terms_df.copy()
        display_df['aliases'] = display_df['aliases'].apply(lambda x: ', '.join(x) if x else '')
        display_df['related_terms'] = display_df['related_terms'].apply(lambda x: ', '.join(x) if x else '')
        
        # ã‚«ãƒ©ãƒ åã‚’æ—¥æœ¬èªã«
        column_mapping = {
            'term': 'ç”¨èª', 'definition': 'å®šç¾©', 'domain': 'åˆ†é‡',
            'aliases': 'é¡ç¾©èª', 'related_terms': 'é–¢é€£èª',
            'confidence_score': 'ä¿¡é ¼åº¦', 'updated_at': 'æ›´æ–°æ—¥æ™‚'
        }
        # Add 'id' mapping only if it exists
        if 'id' in display_df.columns:
            column_mapping['id'] = 'ID'
        display_df.rename(columns=column_mapping, inplace=True)
        
        # å‰Šé™¤ãƒœã‚¿ãƒ³ç”¨ã®åˆ—ã‚’è¿½åŠ 
        display_df['å‰Šé™¤'] = False
        
        edited_df = st.data_editor(
            display_df[['ç”¨èª', 'å®šç¾©', 'åˆ†é‡', 'é¡ç¾©èª', 'é–¢é€£èª', 'ä¿¡é ¼åº¦', 'æ›´æ–°æ—¥æ™‚', 'å‰Šé™¤']],
            use_container_width=True,
            hide_index=True,
            height=min(600, (len(display_df) + 1) * 35 + 3),
            column_config={
                "å‰Šé™¤": st.column_config.CheckboxColumn(
                    "å‰Šé™¤",
                    default=False,
                )
            },
            key="dictionary_editor"
        )
        
        terms_to_delete = edited_df[edited_df['å‰Šé™¤']]
        if not terms_to_delete.empty:
            if st.button("é¸æŠã—ãŸç”¨èªã‚’å‰Šé™¤", type="primary"):
                terms_list = terms_to_delete['ç”¨èª'].tolist()
                deleted_count, error_count = rag_system.delete_jargon_terms(terms_list)
                if deleted_count:
                    st.success(f"{deleted_count}ä»¶ã®ç”¨èªã‚’å‰Šé™¤ã—ã¾ã—ãŸã€‚")
                if error_count:
                    st.warning(f"{error_count}ä»¶ã®å‰Šé™¤ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
                get_all_terms_cached.clear()
                st.rerun()

    # CSV download
    st.markdown("---")
    with st.expander("âš ï¸ ç”¨èªè¾æ›¸ã‚’å…¨å‰Šé™¤ã™ã‚‹"):
        st.warning("ã“ã®æ“ä½œã¯å–ã‚Šæ¶ˆã›ã¾ã›ã‚“ã€‚å…¨ã¦ã®å°‚é–€ç”¨èªãƒ¬ã‚³ãƒ¼ãƒ‰ãŒå‰Šé™¤ã•ã‚Œã¾ã™ã€‚", icon="âš ï¸")
        if st.button("â€¼ï¸ å…¨ç”¨èªã‚’å‰Šé™¤", type="secondary"):
            deleted_count, error_count = rag_system.delete_jargon_terms(terms_df['term'].tolist())
            if deleted_count:
                st.success(f"{deleted_count}ä»¶ã®ç”¨èªã‚’å‰Šé™¤ã—ã¾ã—ãŸã€‚")
            if error_count:
                st.warning(f"{error_count}ä»¶ã®å‰Šé™¤ã«å¤±æ•—ã—ã¾ã—ãŸã€‚", icon="âš ï¸")
            get_all_terms_cached.clear()
            st.rerun()
    csv = terms_df.to_csv(index=False)
    st.download_button(
        label="ğŸ“¥ è¡¨ç¤ºä¸­ã®ç”¨èªã‚’CSVã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
        data=csv,
        file_name=f"jargon_dictionary_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
        mime="text/csv",
        key="csv_download_button"
    )
